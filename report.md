# 1. 实验总概
## 1.1. 问题重述
本次实验我们小组的选题是实现KNN（k nearest neighbors）算法，具体可以描述如下：

    对于每个查询集点，找到离它最近（欧几里得距离）的k个参考集点，返回结果包括k个距离集和k个下标集。
    
下文用这些变量代替数据集/数据：

    - 参考集  ：ref
    - 查询集  ：query
    - 距离集  ：knn_dist
    - 下标集  ：knn_idx
    - 数据维度：dim
    - 最近邻数：k

其中，参考集和查询集都被设置为大小为n\*dim的数组，每dim个元素代表一个数据点；距离集和下标集都被设置为大小为query_num\*k的数组，每k个元素代表着某个查询点的K近邻（距离或下标）。
## 1.2. 预期完成目标
- 利用归约实现KNN
- KD树实现KNN
## 1.3. 实际完成内容
- 合理使用shared memory加速计算欧式距离
- 归约实现KNN
- $---------待补充---------$
## 1.4. 实施方案
$---------待补充---------$
# 2. 程序逻辑及功能介绍
此部分说明本次实验中所设计的函数以及程序的逻辑，并介绍其功能、算法和实现。
## 2.1. 基本部分
此小节介绍和并行化基本无关的函数，包括随机初始化矩阵、判断KNN结果正确（相同）和CPU版本的KNN算法等。

通过此部分，我们可以计算出CPU版本的KNN算法的运行结果和运行时间，以此作为对比，并且可以验证后续并行算法结果是否正确。

### 2.1.1. *initialize_data*
本函数初始化矩阵（向量）参考集ref和查询集query，固定随机数种子为12345便于复现结果。
### 2.1.2. *issame*
本函数判断两个数组是否相等。
通过使用此函数判断KNN结果的下标集knn_idx是否相同，从而判断KNN是否结果正确。
### 2.1.3. *knn_cpu*
cpu实现KNN算法，程序逻辑大致如下：

    对于每个查询点，计算其和各个参考点之间的距离，并维护一个大小为k的有序数组，通过类似插入排序的方式不断更新此有序数组。最终将query_num个大小为k的有序数组组合，即是knn_dist，而计算knn_idx只需在计算knn_dist时随之改动下标即可。

本函数还调用了 *compute_distance* 以计算欧氏距离，由于此函数很简单，在此不赘述。

## 2.2. 距离计算优化 + 归约

本小节介绍了使用CUDA实现KNN算法的baseline，并且基于此baseline使用共享内存优化了点与点之间的距离计算方式。

在上述实现的基础上，我们进一步地采用归约对寻找KNN过程进行了优化，并通过修改线程块大小实现了性能的更大提升。

本小节内主函数的逻辑均如下：

    1. 申请内存并拷贝数组
    2. 计算每个查询点和每个参考点之间的距离
    3. 基于距离，得出每个查询点的最近k个邻居

### 2.2.1. *knn_v1*
该函数为CUDA实现knn的baseline版本：
- 对于（2. 计算距离） 使用核函数 *compute_distance_ref2query*，该核函数用最朴素的方法计算两个点之间的距离，即

        令每个线程（坐标为(x，y)）计算第x个查询点（query的第x行）和第y个参考点（ref的第y行）之间的距离。
    由于不使用共享内存，因此每个线程需要访问全局内存2\*dim次。
- 对于（3. 寻找k近邻）使用核函数*find_nearest_k_neighbors*，该核函数对于每个查询点均开辟一个线程，对*compute_distance_ref2query* 得出的distance矩阵（query_num \* ref_num）中每一行，执行类似插入排序（在大小为k的数组中插入排序）的操作，这一操作与 *knn_cpu* 中找到k近邻类似。

### 2.2.2. *knn_v2*
该函数修改baseline中的（2. 计算距离）部分，因为在2.2.1.中，*compute_distance_ref2query* 每个线程都需要访问全局内存2\*dim次。

计算距离的核函数：*compute_distance_sm*

    1. 使用共享内存（shared memory）储存query和ref的一小部分作为子矩阵（因为query和ref可能非常大，故储存一小部分），同步
    2. 同一block内的线程均可以从共享内存中访问数据，计算出一部分的距离，同步
    3. 类似滑窗，移动子矩阵，再读入共享内存，直至矩阵末尾（遍历所有维度）。
按照上述方式使用共享内存，每个线程访问全局内存的次数下降为dim/step，其中step为“窗口”的长度，即每次移动窗口的距离。

### 2.2.3. *knn_v3*
2.2.2.已经较好地解决了（2. 计算距离）的问题，我们将目光放到（3. 寻找k近邻）部分。

不难发现，在给定距离的情况下，（3. 寻找k近邻）是一个天然的归约问题，因此我们尝试使用归约来加速它。通过核函数 *reduction_find_kNN* 实现：

    1. 线程块组织方式为每个block处理一个request，这样有利于使用共享内存储存k近邻
    2. 线程块中每个线程计算其对应子数组中的k个最小值，并将其存到共享内存的对应位置。共享内存大小为k*blocksize
    3. 对共享内存内的数据进行归约。以每k个元素作为一组，两两进行合并，重复多次，直到共享内存大小为64*k
    4. 当共享内存大小为64*k时，使用线程束内归约。（实际代码中没有实现，因为进行合并操作时，会对共享内存同一部分进行访问和修改，这将导致数据不一致问题；如果要解决此问题，则需要额外的开销，性能反而变差）
    5. 将共享内存中前k个距离/下标写回数组中

该核函数中使用了如下设备函数：
- *reduction_operation_unsorted* 将无序的数组化为其中最小k个数构成的数组，用于最初将全局内存中的无序数据存入共享内存中。
- *reduction_operation_sorted* 合并两个有序的、大小为k的数组，这是实际的归约操作

### 2.2.4. *knn_v4*
上一个版本使用归约提高了该算法的性能，而本函数修改了线程块大小（blocksize）为64，使2.2.3.中 *reduction_find_kNN* 的第3步被省去，直接进入第4步。

这样做的原因是：减少线程块大小，减少了第2步中的并行数，但增加了每个线程的计算量；而且减少了 *reduction_operation_sorted* 这样一个低消耗资源但多线程的操作。这两者都提升了占用率。

## 2.3. KD树实现
$---------待补充---------$
# 3. 实验结果和加速比
## 3.1. 实验配置
本次实验使用随机生成的数据集进行测试，其中各项参数如下表所示：
| 参数名 | 数值 |
| :----: | :----: |
| 参考集大小 | 8192 |
| 查询集大小 | 512 |
| 数据维度 | 128 |
| 近邻数 | 16 |

实验平台为课程提供的集群。

为了保证实验结果的说服力，除CPU版本的KNN之外，其余版本均重复20次取均值。

## 3.2. 距离计算优化 + 并行归约
本部分介绍2.2.节所使用的距离优化和并行归约的性能提升。

| 方法/函数 | 用时(s) | 加速比 |
| :---: | :---: | :---: |
| knn_cpu | 1.474470 | -
| knn_v1 | 0.020033 | 1.00x |
| knn_v2 | 0.016259 | 1.23x |
| knn_v3 | 0.009480 | 2.11x |
| knn_v4 | 0.008924 | 2.24x |

## 3.3. KD树优化
本部分介绍2.3.节所使用的KD树优化的性能提升。

| 方法/函数 | 用时(s) | 加速比 |
| :---: | :---: | :---: |

## 3.4. 与2018年工作的比较
比较代码来自于 https://github.com/vincentfpgarcia/kNN-CUDA

在控制参数相同的情况下，其性能如下：
| 方法/函数 | 用时(s) |
| :---: | :---: |
| knn_cuda_global | 0.01911 |
| knn_cuda_texture | 0.01466 |
| knn_cublas | 0.01924 |

可以看到，在使用并行归约对knn进行优化之后，我们所写的KNN算法性能已经远远优于该工作了。
